# Python AI Scraper Structure (Clean + Practical)

## ğŸ“ File Organization

```
src/
â”œâ”€â”€ app.py                # FastAPI app setup
â”œâ”€â”€ routes/
â”‚   â””â”€â”€ routes.py         # GET /health + POST /api/scrape/reddit/multi
â”œâ”€â”€ controllers/
â”‚   â”œâ”€â”€ health_controller.py
â”‚   â””â”€â”€ scraper_controller.py
â”œâ”€â”€ scraper/
â”‚   â””â”€â”€ reddit_scraper.py # Reddit scraper + all scraper-related schemas
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ config.py         # getenv() helper
â”‚   â””â”€â”€ logger.py         # logging setup
â””â”€â”€ storage/
    â””â”€â”€ filesystem.py     # optional file storage helpers
```

**Principle:** keep â€œscraper-related dataâ€ (schemas + scraping logic) inside the scraper module(s), and keep the API layer thin.

## ğŸ¯ Key Principles

1. **Scraper module owns scraper data** - request/response schemas + scraping logic live together
2. **Thin API layer** - routes call scraper module directly
3. **Easy to extend** - add new modules under `src/scraper/` and expose new routes
4. **Neat structure** - minimal folders, no redundant â€œdomain/controllerâ€ layers

## ğŸ“ Usage Examples

### Basic Usage
```python
from src.scraper.reddit_scraper import RedditScraper, RedditMultiScrapeRequest

scraper = RedditScraper()
posts = scraper.scrape_subreddits(
    RedditMultiScrapeRequest(subreddits=["python", "learnpython"], limit=3, sort_by="hot")
)
print(len(posts))
```

## ğŸ”§ Adding New Sources

Just add a new module under `src/scraper/` (example: `hackernews_scraper.py`) and call it from a route in `src/routes/`.

## âœ¨ Benefits

- âœ… **Simpler** - no redundant layering
- âœ… **Cleaner** - scraper logic is centralized in the scraper module(s)
- âœ… **Flexible** - easy to add new sources/routes

  